// --- DOMè¦ç´ ã®å–å¾— ---
const overallStartBtn = document.getElementById('overall-start-btn'); // å…¨ä½“é–‹å§‹ãƒœã‚¿ãƒ³
const initialStartSection = document.getElementById('initial-start-section'); // åˆæœŸè¡¨ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³

const interviewSection = document.getElementById('interview-section');
const questionDisplay = document.getElementById('question-display');
const userAnswerDisplay = document.getElementById('user-answer-display');
const feedbackDisplay = document.getElementById('feedback-display');
const micToggleBtn = document.getElementById('mic-toggle-btn');
const nextQuestionBtn = document.getElementById('next-question-btn');
const resetInterviewBtn = document.getElementById('reset-interview-btn');
const statusMessage = document.getElementById('status-message');
const errorMessage = document.getElementById('error-message');

// --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ---
let allQuestions = []; // å…¨ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰èª­ã¿è¾¼ã‚“ã è³ªå•ãƒªã‚¹ãƒˆ
let currentQuestionIndex = 0;
let recognition;
let isMicActive = false;
let recognitionTimeout;

// --- å®šæ•° ---
const ANSWER_TIME_LIMIT_SECONDS = 30;
const QUESTION_SPEECH_RATE = 1.2;

// --- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼URL ---
const BACKEND_API_URL = 'http://localhost:3000/api/get-feedback';

// --- åˆæœŸåŒ– ---
document.addEventListener('DOMContentLoaded', async () => {
    try {
        const response = await fetch('questions.json');
        if (!response.ok) throw new Error(`Failed to load questions.json: ${response.statusText}`);
        const questionsData = await response.json();

        for (const category in questionsData) {
            allQuestions = allQuestions.concat(questionsData[category]);
        }

        initSpeechRecognition();
        statusMessage.textContent = "æº–å‚™ãŒã§ãã¾ã—ãŸã€‚";
    } catch (error) {
        showError(`åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: ${error.message}`);
        overallStartBtn.disabled = true;
    }
});

// --- éŸ³å£°èªè­˜ã®åˆæœŸåŒ– ---
function initSpeechRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
        showError("ãƒ–ãƒ©ã‚¦ã‚¶ãŒéŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ï¼ˆChromeæ¨å¥¨ï¼‰");
        micToggleBtn.disabled = true;
        overallStartBtn.disabled = true;
        return;
    }

    recognition = new SpeechRecognition();
    recognition.lang = 'ja-JP';
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onstart = () => {
        let timeLeft = ANSWER_TIME_LIMIT_SECONDS;
        statusMessage.textContent = `ğŸ™ï¸ è©±ã—ã¦ãã ã•ã„... (æ®‹ã‚Š ${timeLeft}ç§’)`;
        micToggleBtn.textContent = "ğŸ™ï¸ å›ç­”ä¸­...";
        micToggleBtn.disabled = true;
        nextQuestionBtn.disabled = true;
        isMicActive = true;

        recognitionTimeout = setInterval(() => {
            timeLeft--;
            if (timeLeft <= 0) {
                clearInterval(recognitionTimeout);
                if (isMicActive) {
                    recognition.stop();
                    statusMessage.textContent = "å›ç­”æ™‚é–“çµ‚äº†ã€‚";
                }
            } else {
                statusMessage.textContent = `ğŸ™ï¸ å›ç­”ä¸­... (æ®‹ã‚Š ${timeLeft}ç§’)`;
            }
        }, 1000);
    };

    recognition.onresult = async (event) => {
        clearInterval(recognitionTimeout);
        const transcript = event.results[0][0].transcript;
        userAnswerDisplay.textContent = transcript;
        statusMessage.textContent = "å›ç­”ã‚’èªè­˜ã—ã¾ã—ãŸã€‚AIã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆä¸­...";

        try {
            const feedback = await getGPTFeedback(questionDisplay.textContent, transcript);
            feedbackDisplay.textContent = feedback;
        } catch (error) {
            showError(`ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å–å¾—ã‚¨ãƒ©ãƒ¼: ${error.message}`);
            feedbackDisplay.textContent = "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚";
        } finally {
            micToggleBtn.textContent = "ğŸ™ï¸ å›ç­”ã™ã‚‹";
            micToggleBtn.disabled = false;
            nextQuestionBtn.disabled = false;
            isMicActive = false;
        }
    };

    recognition.onerror = (event) => {
        clearInterval(recognitionTimeout);
        statusMessage.textContent = `âš ï¸ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${event.error}`;
        micToggleBtn.textContent = "ğŸ™ï¸ å›ç­”ã™ã‚‹";
        micToggleBtn.disabled = false;
        nextQuestionBtn.disabled = false;
        isMicActive = false;
        showError(`éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${event.error}`);
    };

    recognition.onend = () => {
        if (isMicActive) {
            clearInterval(recognitionTimeout);
            statusMessage.textContent = "å›ç­”æ™‚é–“çµ‚äº†ã¾ãŸã¯èªè­˜çµ‚äº†ã€‚ã‚‚ã†ä¸€åº¦å›ç­”ã—ã¦ãã ã•ã„ã€‚";
            micToggleBtn.textContent = "ğŸ™ï¸ å›ç­”ã™ã‚‹";
            micToggleBtn.disabled = false;
            nextQuestionBtn.disabled = false;
            isMicActive = false;
        }
    };
}

// --- ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ ---
overallStartBtn.addEventListener('click', startInterviewFlow);
micToggleBtn.addEventListener('click', toggleMic);
nextQuestionBtn.addEventListener('click', displayNextQuestion);
resetInterviewBtn.addEventListener('click', resetInterview);

// --- é¢æ¥é–‹å§‹ ---
function startInterviewFlow() {
    if (allQuestions.length === 0) {
        showError("è³ªå•ãŒã‚ã‚Šã¾ã›ã‚“ã€‚questions.jsonã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚");
        return;
    }
    initialStartSection.classList.add('hidden');
    interviewSection.classList.remove('hidden');
    currentQuestionIndex = 0;
    displayNextQuestion();
}

// --- æ¬¡ã®è³ªå•ã‚’è¡¨ç¤º ---
function displayNextQuestion() {
    if (currentQuestionIndex < allQuestions.length) {
        const question = allQuestions[currentQuestionIndex];
        questionDisplay.textContent = question;
        userAnswerDisplay.textContent = "";
        feedbackDisplay.textContent = "";
        statusMessage.textContent = "è³ªå•ã‚’èª­ã¿ä¸Šã’ã¾ã™...";

        const utter = new SpeechSynthesisUtterance(question);
        utter.lang = 'ja-JP';
        utter.rate = QUESTION_SPEECH_RATE;
        utter.onend = () => {
            statusMessage.textContent = "å›ç­”ã—ã¦ãã ã•ã„ã€‚";
            micToggleBtn.disabled = false;
        };
        speechSynthesis.speak(utter);

        currentQuestionIndex++;
    } else {
        questionDisplay.textContent = "é¢æ¥ã¯çµ‚äº†ã§ã™ã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼";
        feedbackDisplay.textContent = "å…¨ã¦ã®è³ªå•ã«å›ç­”ã—ã¾ã—ãŸã€‚";
        micToggleBtn.disabled = true;
        nextQuestionBtn.disabled = true;
    }
}

// --- ãƒã‚¤ã‚¯æ“ä½œ ---
function toggleMic() {
    if (isMicActive) {
        recognition.stop();
    } else {
        userAnswerDisplay.textContent = "";
        feedbackDisplay.textContent = "";
        recognition.start();
    }
}

// --- ãƒªã‚»ãƒƒãƒˆ ---
function resetInterview() {
    currentQuestionIndex = 0;
    questionDisplay.textContent = "é¢æ¥ã‚’é–‹å§‹ã™ã‚‹ã«ã¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚";
    userAnswerDisplay.textContent = "";
    feedbackDisplay.textContent = "";
    statusMessage.textContent = "";
    micToggleBtn.disabled = true;
    nextQuestionBtn.disabled = true;
    interviewSection.classList.add('hidden');
    initialStartSection.classList.remove('hidden');
    hideError();
}

// --- GPTãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å‘¼ã³å‡ºã— ---
async function getGPTFeedback(question, answer) {
    const response = await fetch(BACKEND_API_URL, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ question, answer })
    });
    if (!response.ok) throw new Error(`APIã‚¨ãƒ©ãƒ¼: ${response.statusText}`);
    const data = await response.json();
    return data.feedback;
}

// --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---
function showError(message) {
    errorMessage.textContent = message;
    errorMessage.classList.remove('hidden');
}
function hideError() {
    errorMessage.classList.add('hidden');
    errorMessage.textContent = "";
}
